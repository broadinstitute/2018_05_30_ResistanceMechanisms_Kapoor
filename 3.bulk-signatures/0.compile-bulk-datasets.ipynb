{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "from pycytominer import feature_select\n",
    "from pycytominer.cyto_utils import infer_cp_features, write_gct\n",
    "\n",
    "sys.path.insert(0, \"../2.describe-data/scripts\")\n",
    "from processing_utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"four_clone\", \"cloneAE\"]\n",
    "data_dir = pathlib.Path(\"../0.generate-profiles/profiles\")\n",
    "cell_count_dir = pathlib.Path(\"../0.generate-profiles/cell_counts/\")\n",
    "\n",
    "output_dir = pathlib.Path(\"data\")\n",
    "batches = [\n",
    "    \"2019_11_11_Batch4\",\n",
    "    \"2019_11_19_Batch5\",\n",
    "    \"2019_11_20_Batch6\",\n",
    "    \"2019_11_22_Batch7\",\n",
    "    \"2020_07_02_Batch8\",\n",
    "]\n",
    "\n",
    "profile_suffix = \"normalized.csv.gz\"\n",
    "\n",
    "feature_select_opts = [\n",
    "    \"variance_threshold\",\n",
    "    \"correlation_threshold\",\n",
    "    \"drop_na_columns\",\n",
    "    \"blocklist\",\n",
    "    \"drop_outliers\",\n",
    "]\n",
    "corr_threshold = 0.95\n",
    "na_cutoff = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {x: [] for x in datasets}\n",
    "common_meta = []\n",
    "for batch in batches:\n",
    "    # Load and harmonize data\n",
    "    df = load_data(\n",
    "        batch=batch,\n",
    "        profile_dir=data_dir,\n",
    "        suffix=profile_suffix,\n",
    "        combine_dfs=True,\n",
    "        harmonize_cols=True,\n",
    "        cell_count_dir=cell_count_dir\n",
    "    )\n",
    "    \n",
    "    # Add important metadata features\n",
    "    df = df.assign(\n",
    "        Metadata_batch=batch,\n",
    "        Metadata_clone_type=\"resistant\",\n",
    "        Metadata_clone_type_indicator=1\n",
    "    )\n",
    "    df.loc[df.Metadata_clone_number.str.contains(\"WT\"), \"Metadata_clone_type\"] = \"sensitive\"\n",
    "    df.loc[df.Metadata_clone_number.str.contains(\"WT\"), \"Metadata_clone_type_indicator\"] = 0\n",
    "\n",
    "    # Get metadata features    \n",
    "    meta = infer_cp_features(df, metadata=True)\n",
    "    common_meta.append(set(meta))\n",
    "\n",
    "    # Store in dictionary\n",
    "    if batch == \"2020_07_02_Batch8\":\n",
    "        df_index = \"cloneAE\"\n",
    "    else:\n",
    "        df_index = \"four_clone\"\n",
    "\n",
    "    dfs[df_index].append(df)\n",
    "\n",
    "common_metadata = list(set.intersection(*common_meta)) + [\"Metadata_sample_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "four_clone\n",
      "(420, 3538)\n",
      "cloneAE\n",
      "(240, 3538)\n"
     ]
    }
   ],
   "source": [
    "for dataset in dfs:\n",
    "    bulk_df = pd.concat(dfs[dataset], sort=False).reset_index(drop=True)\n",
    "    \n",
    "    # Set sample index metadata feature\n",
    "    bulk_df = bulk_df.assign(\n",
    "        Metadata_sample_index=[f\"sample_index_{x}\" for x in range(0, bulk_df.shape[0])]\n",
    "    )\n",
    "    \n",
    "    # Reorder features\n",
    "    feat = infer_cp_features(bulk_df)\n",
    "\n",
    "    bulk_df = (\n",
    "        bulk_df\n",
    "        .reindex(common_metadata + feat, axis=\"columns\")\n",
    "    )\n",
    "\n",
    "    dfs[dataset] = bulk_df\n",
    "    \n",
    "    print(dataset)\n",
    "    print(bulk_df.shape)\n",
    "\n",
    "common_metadata = set.intersection(*common_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature selection and track which features are selected for the analysis\n",
    "feature_select_dfs = {}\n",
    "selected_features = []\n",
    "for dataset in datasets:\n",
    "    # Apply feature selection\n",
    "    feature_select_dfs[dataset] = feature_select(\n",
    "        dfs[dataset],\n",
    "        operation=feature_select_opts,\n",
    "        na_cutoff=na_cutoff,\n",
    "    )\n",
    "\n",
    "    dataset_features = infer_cp_features(feature_select_dfs[dataset])\n",
    "\n",
    "    selected_features.append(\n",
    "        pd.DataFrame(dataset_features, columns=[\"features\"])\n",
    "        .assign(dataset=dataset)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cells_AreaShape_Compactness</td>\n",
       "      <td>four_clone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cells_AreaShape_Extent</td>\n",
       "      <td>four_clone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cells_AreaShape_FormFactor</td>\n",
       "      <td>four_clone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cells_AreaShape_Solidity</td>\n",
       "      <td>four_clone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cells_AreaShape_Zernike_1_1</td>\n",
       "      <td>four_clone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      features     dataset\n",
       "0  Cells_AreaShape_Compactness  four_clone\n",
       "1       Cells_AreaShape_Extent  four_clone\n",
       "2   Cells_AreaShape_FormFactor  four_clone\n",
       "3     Cells_AreaShape_Solidity  four_clone\n",
       "4  Cells_AreaShape_Zernike_1_1  four_clone"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output results of feature selection\n",
    "all_selected_features = pd.concat(selected_features).reset_index(drop=True)\n",
    "\n",
    "output_file = pathlib.Path(f\"{output_dir}/dataset_features_selected.tsv\")\n",
    "all_selected_features.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "all_selected_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 338)\n",
      "(240, 434)\n"
     ]
    }
   ],
   "source": [
    "print(feature_select_dfs[\"four_clone\"].shape)\n",
    "print(feature_select_dfs[\"cloneAE\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Datasets\n",
    "\n",
    "We output the feature selected datasets as .gct files, but the full feature set as compressed csvs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in dfs:\n",
    "    output_file = pathlib.Path(f\"{output_dir}/bulk_profiles_{dataset}.csv.gz\")\n",
    "    output_gct_file = pathlib.Path(f\"{output_dir}/bulk_profiles_feature_select_{dataset}.gct\")\n",
    "    \n",
    "    dfs[dataset].to_csv(output_file, sep=\",\", compression=\"gzip\", index=False)\n",
    "    write_gct(profiles=feature_select_dfs[dataset], output_file=output_gct_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
